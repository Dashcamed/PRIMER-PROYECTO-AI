{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XArH64-HD6pb",
    "outputId": "bf501833-6db0-4883-f875-c85aba1c9b11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\camil\\miniconda3\\envs\\generacion-de-prompts\\lib\\site-packages (0.28.0)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\camil\\miniconda3\\envs\\generacion-de-prompts\\lib\\site-packages (from openai) (2.32.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\camil\\miniconda3\\envs\\generacion-de-prompts\\lib\\site-packages (from openai) (4.66.4)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\camil\\miniconda3\\envs\\generacion-de-prompts\\lib\\site-packages (from openai) (3.9.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\camil\\miniconda3\\envs\\generacion-de-prompts\\lib\\site-packages (from requests>=2.20->openai) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\camil\\miniconda3\\envs\\generacion-de-prompts\\lib\\site-packages (from requests>=2.20->openai) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\camil\\miniconda3\\envs\\generacion-de-prompts\\lib\\site-packages (from requests>=2.20->openai) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\camil\\miniconda3\\envs\\generacion-de-prompts\\lib\\site-packages (from requests>=2.20->openai) (2024.7.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\camil\\miniconda3\\envs\\generacion-de-prompts\\lib\\site-packages (from aiohttp->openai) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\camil\\miniconda3\\envs\\generacion-de-prompts\\lib\\site-packages (from aiohttp->openai) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\camil\\miniconda3\\envs\\generacion-de-prompts\\lib\\site-packages (from aiohttp->openai) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\camil\\miniconda3\\envs\\generacion-de-prompts\\lib\\site-packages (from aiohttp->openai) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\camil\\miniconda3\\envs\\generacion-de-prompts\\lib\\site-packages (from aiohttp->openai) (1.9.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\camil\\miniconda3\\envs\\generacion-de-prompts\\lib\\site-packages (from tqdm->openai) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai\n",
    "\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "x1MFa2dYFuuw"
   },
   "outputs": [],
   "source": [
    "openai.api_key = \"tu api key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 460
    },
    "id": "YK8PPNV_GxFr",
    "outputId": "cd9e7fb8-3b73-41de-e2a9-123d32067483"
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Necesitas una receta de (Cocina/Pasteleria/Panaderia):  pasteleria\n",
      "Alguna receta en especifico? (Y/N) y\n",
      "Escribe el producto que quieres por ejemplo, Torta de tres leches... merengue italiano\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Has solicitado una receta de: Merengue italiano\n",
      "Has seleccionado: Pasteleria\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "¿Necesitas la receta en porcentajes? (Y/N)?  y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En Porcentajes\n",
      "¡Claro! Aquí te dejo una receta de Merengue Italiano calculada en porcentajes, que puedes usar en tu negocio gastronómico:\n",
      "\n",
      "Ingredientes:\n",
      "- 100% claras de huevo\n",
      "- 200% azúcar\n",
      "- 50% agua\n",
      "\n",
      "Procedimiento:\n",
      "1. En una olla pequeña, combina el azúcar y el agua.\n",
      "2. Lleva la mezcla a fuego medio y cocina hasta que alcance los 118°C (240°F) en un termómetro de dulces.\n",
      "3. Mientras tanto, coloca las claras de huevo en un tazón limpio y comienza a batirlas a velocidad media.\n",
      "4. Cuando el almíbar alcance la temperatura deseada, retíralo del fuego y viértelo lentamente sobre las claras montadas, batiendo constantemente.\n",
      "5. Continúa batiendo hasta que la mezcla se enfríe y tenga una consistencia firme y brillante.\n",
      "\n",
      "Este merengue italiano es perfecto para decorar postres como macarons, tartas y cupcakes. ¡Espero que esta receta sea de utilidad para tu negocio gastronómico!\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "context = \"Eres un chef profesional y necesitas una receta para usar en un negocio gastronómico\"\n",
    "continue_loop = True\n",
    "\n",
    "# pedir mediante un input si necesita una receta de cocina, pasteleria o panaderia\n",
    "while continue_loop:\n",
    "    recipe = input(\"Necesitas una receta de (Cocina/Pasteleria/Panaderia): \")\n",
    "    specific_recipe = input(\"Alguna receta en especifico? (Y/N)\")\n",
    "\n",
    "    if specific_recipe.upper() == \"Y\":\n",
    "        specific_recipe_of = input(\"Escribe el producto que quieres por ejemplo, Torta de tres leches...\")\n",
    "        print(f\"Has solicitado una receta de: {specific_recipe_of.capitalize()}\")\n",
    "    else:\n",
    "        print(f\"Has solicitado una receta aleatoria: {recipe.capitalize()}\")\n",
    "\n",
    "    if recipe.lower() in [\"cocina\", \"pasteleria\", \"panaderia\"]:\n",
    "        type_of_recipe = recipe.lower()\n",
    "        print(f\"Has seleccionado: {type_of_recipe.capitalize()}\")\n",
    "\n",
    "        calculate_recipe = input(\"¿Necesitas la receta en porcentajes? (Y/N)? \")\n",
    "\n",
    "        if calculate_recipe.upper() == \"Y\":\n",
    "            print(\"En Porcentajes\")\n",
    "            calculate_recipe_format = \"en porcentajes\"\n",
    "        else:\n",
    "            print(\"En gramajes\")\n",
    "            calculate_recipe_format = \"en gramajes\"\n",
    "\n",
    "        prompt = f\"Trae una receta de los mejores libros de gastronomía de {type_of_recipe.capitalize()} de {specific_recipe_of.capitalize()} calculada {calculate_recipe_format} para usarla en mi negocio de gastronomía.\"\n",
    "\n",
    "        # Hacer la solicitud a OpenAI\n",
    "        conversation = [\n",
    "            {\"role\": \"system\", \"content\": context},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model='gpt-3.5-turbo',\n",
    "            messages=conversation,\n",
    "            max_tokens=2000\n",
    "        )\n",
    "\n",
    "        # Almacenar la respuesta en una variable para usarla\n",
    "        phase = response['choices'][0]['message']['content'].strip()\n",
    "\n",
    "        # Usar la variable\n",
    "        print(phase)\n",
    "        continue_loop = False  # Salir del bucle si la entrada es válida\n",
    "\n",
    "    else:\n",
    "        print(\"Entrada no válida. Por favor, ingresa Cocina, Pasteleria o Panaderia.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XrOH9ZmqUFB6"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
