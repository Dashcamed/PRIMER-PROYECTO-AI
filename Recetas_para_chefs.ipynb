{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XArH64-HD6pb",
    "outputId": "bf501833-6db0-4883-f875-c85aba1c9b11",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install -U google-generativeai #instala googleai para buscar las recetas\n",
    "!pip install openai #instala openai para generar la imagen\n",
    "\n",
    "import google.generativeai as genai #importa gemini\n",
    "import openai #importa openai\n",
    "import requests #necesario\n",
    "import os #necesario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "x1MFa2dYFuuw"
   },
   "outputs": [],
   "source": [
    "openai.api_key = \"\" #configura tu apikey de openia\n",
    "genai.configure(api_key=\"\") #configura tu apikey de gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modelo de google\n",
    "generation_config = {\n",
    "    \"temperature\": 0.5,\n",
    "    \"top_p\": 0.95,\n",
    "    \"top_k\": 64,\n",
    "    \"max_output_tokens\": 8192,\n",
    "    \"response_mime_type\": \"text/plain\",\n",
    "}\n",
    "#en el system_instruction se da el contexto, en este caso es un openbook porque le pido que busque en su base de datos la receta.\n",
    "model = genai.GenerativeModel(\n",
    "    model_name=\"gemini-1.5-flash\",\n",
    "    generation_config=generation_config,\n",
    "    system_instruction=\"Eres rat贸n llamado Renly un profesional del mundo gastron贸mico y recomendar谩s las mejores recetas de los mejores libros del mundo. Das las recetas solo en gramajes o porcentajes dependiendo de lo que el usuario te pida. Ademas generas una imagen de la receta con otro modelo por lo que si el usuario te dice no despues de la primera recomendaci贸n es porque no requiri贸 la imagen.\",\n",
    ")\n",
    "\n",
    "history_chat = []\n",
    "# funcion para generar la imagen desde openai\n",
    "def generate_image_with_openai(prompt):\n",
    "    image_response = openai.Image.create(\n",
    "        prompt=prompt,\n",
    "        n=1,\n",
    "        size=\"1024x1024\"\n",
    "    )\n",
    "\n",
    "    # retorna la imagen en una url\n",
    "    response = image_response['data'][0]['url']\n",
    "    return response\n",
    "\n",
    "#funcion para iniciar el chat en un bucle while\n",
    "def chat():\n",
    "    chat_session = model.start_chat(history=history_chat)\n",
    "    \n",
    "    print(\"Soy Renly el rat贸n un reconocido chef. Doy recomendaciones de recetas en gramajes o porcentajes, adelante pideme una receta . Si quieres ir a tu cocina a prepararla, escribe salir para terminar nuestra conversaci贸n.\")\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        user_message = input(\"Tu: \")\n",
    "\n",
    "        if user_message.lower() == \"salir\":  # Salir del chat\n",
    "            break\n",
    "\n",
    "        response = chat_session.send_message(user_message)\n",
    "        print(response.text)\n",
    "\n",
    "        # Actualizar historial con la respuesta de Gemini\n",
    "        history_chat.append({'role': 'user', 'parts': [user_message]})\n",
    "        history_chat.append({'role': 'model', 'parts': [response.text]})\n",
    "\n",
    "        # Despu茅s de la primera respuesta de gemini, se pregunta si se debe generar una imagen\n",
    "        if len(history_chat) == 2:  # Verifica que es la primera interacci贸n completa osea, usuario y modelo.\n",
    "            #pregunta al usuario mediante un si o no si requiere la imagen o no.\n",
    "            generate_image = input(\"驴Deseas generar una imagen con OpenAI basada en tu mensaje? (s铆/no): \").strip().lower()\n",
    "            \n",
    "            if generate_image == \"s铆\" or generate_image == \"si\":\n",
    "                image_url = generate_image_with_openai(user_message)\n",
    "                print(f\"Image URL: {image_url}\")\n",
    "\n",
    "                # Agregar la URL de la imagen al historial\n",
    "                history_chat.append({'role': 'model', 'parts': [f\"Image URL: {image_url}\"]})\n",
    "\n",
    "chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
