{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XArH64-HD6pb",
    "outputId": "bf501833-6db0-4883-f875-c85aba1c9b11",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install -U google-generativeai #instala googleai para buscar las recetas\n",
    "!pip install openai #instala openai para generar la imagen\n",
    "\n",
    "import google.generativeai as genai #importa gemini\n",
    "import openai #importa openai\n",
    "import requests #necesario\n",
    "import os #necesario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "x1MFa2dYFuuw"
   },
   "outputs": [],
   "source": [
    "openai.api_key = \"\" #configura tu apikey de openia\n",
    "genai.configure(api_key=\"\") #configura tu apikey de gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modelo de google\n",
    "generation_config = {\n",
    "    \"temperature\": 0.5,\n",
    "    \"top_p\": 0.95,\n",
    "    \"top_k\": 64,\n",
    "    \"max_output_tokens\": 8192,\n",
    "    \"response_mime_type\": \"text/plain\",\n",
    "}\n",
    "#en el system_instruction se da el contexto, en este caso es un openbook porque le pido que busque en su base de datos la receta.\n",
    "model = genai.GenerativeModel(\n",
    "    model_name=\"gemini-1.5-flash\",\n",
    "    generation_config=generation_config,\n",
    "    system_instruction=\"Eres ratón llamado Renly un profesional del mundo gastronómico y recomendarás las mejores recetas de los mejores libros del mundo. Das las recetas solo en gramajes o porcentajes dependiendo de lo que el usuario te pida. Ademas generas una imagen de la receta con otro modelo por lo que si el usuario te dice no despues de la primera recomendación es porque no requirió la imagen.\",\n",
    ")\n",
    "\n",
    "history_chat = []\n",
    "# funcion para generar la imagen desde openai\n",
    "def generate_image_with_openai(prompt):\n",
    "    image_response = openai.Image.create(\n",
    "        prompt=prompt,\n",
    "        n=1,\n",
    "        size=\"1024x1024\"\n",
    "    )\n",
    "\n",
    "    # retorna la imagen en una url\n",
    "    response = image_response['data'][0]['url']\n",
    "    return response\n",
    "\n",
    "#funcion para iniciar el chat en un bucle while\n",
    "def chat():\n",
    "    chat_session = model.start_chat(history=history_chat)\n",
    "    \n",
    "    print(\"Soy Renly el ratón un reconocido chef. Doy recomendaciones de recetas en gramajes o porcentajes, adelante pideme una receta 🐭. Si quieres ir a tu cocina a prepararla, escribe salir para terminar nuestra conversación.\")\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        user_message = input(\"Tu: \")\n",
    "\n",
    "        if user_message.lower() == \"salir\":  # Salir del chat\n",
    "            break\n",
    "\n",
    "        response = chat_session.send_message(user_message)\n",
    "        print(response.text)\n",
    "\n",
    "        # Actualizar historial con la respuesta de Gemini\n",
    "        history_chat.append({'role': 'user', 'parts': [user_message]})\n",
    "        history_chat.append({'role': 'model', 'parts': [response.text]})\n",
    "\n",
    "        # Después de la primera respuesta de gemini, se pregunta si se debe generar una imagen\n",
    "        if len(history_chat) == 2:  # Verifica que es la primera interacción completa osea, usuario y modelo.\n",
    "            #pregunta al usuario mediante un si o no si requiere la imagen o no.\n",
    "            generate_image = input(\"¿Deseas generar una imagen con OpenAI basada en tu mensaje? (sí/no): \").strip().lower()\n",
    "            \n",
    "            if generate_image == \"sí\" or generate_image == \"si\":\n",
    "                image_url = generate_image_with_openai(user_message)\n",
    "                print(f\"Image URL: {image_url}\")\n",
    "\n",
    "                # Agregar la URL de la imagen al historial\n",
    "                history_chat.append({'role': 'model', 'parts': [f\"Image URL: {image_url}\"]})\n",
    "\n",
    "chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
